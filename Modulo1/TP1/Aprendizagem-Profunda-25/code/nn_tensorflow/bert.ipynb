{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\"\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, Ã© o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jonug\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonug\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5051, 2)\n",
      "Columns: Index(['text', 'source'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, Input, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "\n",
    "# Load dos dados\n",
    "csv_path = '../../datasets/human_or_ai_dataset_small_research_only.csv'  # Change this to your file path\n",
    "df = pd.read_csv(csv_path)\n",
    "# Sanity check!\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "# Split the DataFrame (80% train, 20% test)\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'human']\n",
      "       ai  human\n",
      "2238  1.0    0.0\n",
      "1971  0.0    1.0\n",
      "1882  1.0    0.0\n",
      "429   1.0    0.0\n",
      "2693  0.0    1.0\n",
      "['ai', 'human']\n",
      "       ai  human\n",
      "4832  1.0    0.0\n",
      "483   1.0    0.0\n",
      "2011  0.0    1.0\n",
      "2823  0.0    1.0\n",
      "2394  1.0    0.0\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# text.texts_from_df return two tuples\n",
    "# maxlen means it is considering that much words and rest are getting trucated\n",
    "# preprocess_mode means tokenizing, embedding and transformation of text corpus(here it is considering BERT model)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df=df_train,\n",
    "                                                                   text_column = 'text',\n",
    "                                                                   label_columns = 'source',\n",
    "                                                                   val_df = df_test,\n",
    "                                                                   maxlen = 500,\n",
    "                                                                   preprocess_mode = 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonug\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\initializers\\initializers.py:121: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier(name = 'bert',\n",
    "                             train_data = (X_train, y_train),\n",
    "                             preproc = preproc)\n",
    "\n",
    "#here we have taken batch size as 6 as from the documentation it is recommend to use this with maxlen as 500\n",
    "\n",
    "learner = ktrain.get_learner(model=model, train_data=(X_train, y_train),\n",
    "                   val_data = (X_test, y_test),\n",
    "                   batch_size = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/2\n",
      "674/674 [==============================] - 4996s 7s/step - loss: 0.1692 - accuracy: 0.9314 - val_loss: 0.0529 - val_accuracy: 0.9812\n",
      "Epoch 2/2\n",
      "674/674 [==============================] - 4983s 7s/step - loss: 0.0443 - accuracy: 0.9834 - val_loss: 0.1053 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonug\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Essentially fit is a very basic training loop, whereas fit one cycle uses the one cycle policy callback\n",
    "\n",
    "learner.fit_onecycle(lr = 2e-5, epochs = 2)\n",
    "\n",
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.save('bertinho')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
