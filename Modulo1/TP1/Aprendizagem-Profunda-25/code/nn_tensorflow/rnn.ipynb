{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, é o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our own rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5051, 2)\n",
      "Columns: Index(['text', 'source'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, Input, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parameters\n",
    "max_features = 10000  # Tamanho do vocabulário\n",
    "maxlen = 120  # Tamanho máximo das sequências\n",
    "\n",
    "# Load dos dados\n",
    "csv_path = '../../datasets/human_or_ai_dataset_small_research_only.csv'  # Change this to your file path\n",
    "df = pd.read_csv(csv_path)\n",
    "# Sanity check!\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 0]\n",
      "x_train shape: (4040, 120)\n",
      "y_train shape: (4040,)\n",
      "x_test shape: (1011, 120)\n",
      "y_test shape: (1011,)\n",
      "Sample sequence: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0   14   19    1  738    2 4758\n",
      "  109 3150    5    1  619 1381  564    5    4  220  428    2  187   45\n",
      " 2567  724 3261  111   14 1026    1 3273  482 1822   22 5021    5   38\n",
      "  111    3   57    8  109    7  244    9    1  623  158  803 7358 3261\n",
      "   44   14  143    8 1822 7520   96    1  531  373    7  130 3668   14\n",
      "   57    8  109    7   30  244    5    4 6789   44   10   23  433  472\n",
      "    6  266   22 1935    5  531   45   66]\n",
      "Sample label: 0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Separar os textos das labels\n",
    "texts = df['text'].values\n",
    "labels = df['source'].values\n",
    "\n",
    "# Criar um tokenizer\n",
    "tokenizer = preprocessing.text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Converter os textos para sequências de inteiros\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Padding para uniformizar tamanhos\n",
    "x_data = preprocessing.sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Garantir label numérica\n",
    "if not np.issubdtype(labels.dtype, np.number):\n",
    "    label_map = {'human': 0, 'ai': 1}\n",
    "    y_data = np.array([label_map[label] for label in labels])\n",
    "else:\n",
    "    y_data = labels\n",
    "print(y_data)\n",
    "# Data split !\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check shapes\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Print a sample\n",
    "print(\"Sample sequence:\", x_train[0])\n",
    "print(\"Sample label:\", y_train[0])\n",
    "\n",
    "# Save tokenizer to a file\n",
    "with open('tokenizerRNN.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input((maxlen,))) \n",
    "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
    "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer='adam',  \n",
    "    loss='binary_crossentropy',  \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Salvar o melhor modelo\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_rnn.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Treinar o modelo com callbacks\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10, \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Accuracy no teste: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,419,905</span> (5.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,419,905\u001b[0m (5.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,419,905</span> (5.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,419,905\u001b[0m (5.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input((maxlen,))) \n",
    "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.5781 - loss: 0.6631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 339ms/step - accuracy: 0.5815 - loss: 0.6608 - val_accuracy: 0.8899 - val_loss: 0.3435\n",
      "Epoch 2/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.9045 - loss: 0.2710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 339ms/step - accuracy: 0.9052 - loss: 0.2691 - val_accuracy: 0.9084 - val_loss: 0.2173\n",
      "Epoch 3/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9604 - loss: 0.1169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 333ms/step - accuracy: 0.9605 - loss: 0.1164 - val_accuracy: 0.9332 - val_loss: 0.2598\n",
      "Epoch 4/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 336ms/step - accuracy: 0.9798 - loss: 0.0669 - val_accuracy: 0.9307 - val_loss: 0.1989\n",
      "Epoch 5/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 336ms/step - accuracy: 0.9912 - loss: 0.0288 - val_accuracy: 0.9245 - val_loss: 0.2325\n",
      "Epoch 6/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 350ms/step - accuracy: 0.9920 - loss: 0.0268 - val_accuracy: 0.9307 - val_loss: 0.2230\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9400 - loss: 0.2317\n",
      "Accuracy no teste: 0.9387\n"
     ]
    }
   ],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer='adam',  \n",
    "    loss='binary_crossentropy',  \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Salvar o melhor modelo\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_rnn_lstm_epochs.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Treinar o modelo com callbacks\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50, \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Accuracy no teste: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input((maxlen,))) \n",
    "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer='adam',  \n",
    "    loss='binary_crossentropy',  \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Salvar o melhor modelo\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_rnn_gru.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Treinar o modelo com callbacks\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10, \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Accuracy no teste: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting for the Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('best_model_rnn_gru.h5')\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Carregar o CSV com dados para prever\n",
    "prediction_csv_path = '../../datasets/dataset1_inputs.csv'\n",
    "df_predict = pd.read_csv(prediction_csv_path,sep=\"\\t\")\n",
    "\n",
    "# Verificar os dados carregados\n",
    "print(\"Prediction dataset shape:\", df_predict.shape)\n",
    "print(\"Columns:\", df_predict.columns)\n",
    "print(\"Sample IDs:\", df_predict['ID'].head())\n",
    "\n",
    "# Pré-processar os dados de texto para corresponder ao formato de treinamento\n",
    "# Converter textos para sequências\n",
    "sequences = tokenizer.texts_to_sequences(df_predict['Text'].values)\n",
    "\n",
    "# Padding das sequências para o mesmo tamanho usado no treinamento\n",
    "x_predict = preprocessing.sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Fazer previsões com o modelo treinado\n",
    "predictions = model.predict(x_predict)\n",
    "\n",
    "# Converter probabilidades para labels binários (0 = Human, 1 = AI)\n",
    "# Usando 0.5 como threshold - você pode ajustar isso conforme necessário\n",
    "labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Mapear labels para \"AI\" e \"Human\"\n",
    "label_mapping = {1: \"AI\", 0: \"Human\"}\n",
    "labels_mapped = [label_mapping[label] for label in labels.flatten()]\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': df_predict['ID'],\n",
    "    'Label': labels_mapped\n",
    "})\n",
    "\n",
    "# Exibir uma amostra dos resultados\n",
    "print(\"\\nAmostra dos resultados de previsão:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Salvar em CSV\n",
    "output_csv_path = 'prediction_results3.csv'\n",
    "results_df.to_csv(output_csv_path, sep=\"\\t\", index=False)\n",
    "print(f\"\\nResultados salvos em {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
