{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do Dataset\n",
    "Primeiramente, pretendemos agrupar diversos datasets, utilizando duas colunas: \"text\", texto plano, sendo a segunda coluna a label \"source\" que categoriza o texto como \"human\" ou \"ai\".\n",
    "O segundo passo é extrair as _features_ necessárias para treinar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, é o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montar o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"artem9k/ai-text-detection-pile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  12 Years a Slave: An Analysis of the Film Essa...  human\n",
       "1  20+ Social Media Post Ideas to Radically Simpl...  human\n",
       "2  2022 Russian Invasion of Ukraine in Global Med...  human\n",
       "3  533 U.S. 27 (2001) Kyllo v. United States: The...  human\n",
       "4  A Charles Schwab Corporation Case Essay\\n\\nCha...  human"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(ds['train'])\n",
    "df_1.drop(columns=['id'], inplace=True)\n",
    "\n",
    "df_1 = df_1.iloc[:, [1,0]]\n",
    "dataframes.append(df_1)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds2 = load_dataset(\"dmitva/human_ai_generated_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(ds2['train'])\n",
    "\n",
    "# Create a DataFrame for human text\n",
    "df_human = df_2[['human_text']].copy()\n",
    "df_human = df_human.rename(columns={'human_text': 'text'})\n",
    "df_human['source'] = 'human'\n",
    "\n",
    "# Create a DataFrame for AI text\n",
    "df_ai = df_2[['ai_text']].copy()\n",
    "df_ai = df_ai.rename(columns={'ai_text': 'text'})\n",
    "df_ai['source'] = 'ai'\n",
    "\n",
    "# Combine the two DataFrames into one\n",
    "new_df_2 = pd.concat([df_human, df_ai], ignore_index=True)\n",
    "dataframes.append(new_df_2)\n",
    "new_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(new_df_2['source'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terceiro Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds_abs = load_dataset(\"NicolaiSivesind/human-vs-machine\", \"research_abstracts_labeled\")\n",
    "ds_wiki = load_dataset(\"NicolaiSivesind/human-vs-machine\", \"wiki_labeled\")\n",
    "\n",
    "df_3_1_1 = pd.DataFrame(ds_abs['train'])\n",
    "df_3_1_2 = pd.DataFrame(ds_abs['validation'])\n",
    "df_3_1_3 = pd.DataFrame(ds_abs['test'])\n",
    "\n",
    "df_3_2_1 = pd.DataFrame(ds_wiki['train'])\n",
    "df_3_2_2 = pd.DataFrame(ds_wiki['validation'])\n",
    "df_3_2_3 = pd.DataFrame(ds_wiki['test'])\n",
    "\n",
    "df_3 = pd.concat([df_3_1_1, df_3_1_2, df_3_1_3, df_3_2_1, df_3_2_2, df_3_2_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coupling losses were studied in composite tape...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this study, we investigate the coupling los...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let $\\mathsf M_{\\mathsf S}$ denote the strong ...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper, we investigate Weighted Solyani...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 2019 October Betelgeuse began a decline in ...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  Coupling losses were studied in composite tape...  human\n",
       "1  In this study, we investigate the coupling los...     ai\n",
       "2  Let $\\mathsf M_{\\mathsf S}$ denote the strong ...  human\n",
       "3  In this paper, we investigate Weighted Solyani...     ai\n",
       "4  In 2019 October Betelgeuse began a decline in ...  human"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping for the label values\n",
    "label_to_source = {\n",
    "    0: \"human\",\n",
    "    1: \"ai\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the \"source\" column\n",
    "df_3['source'] = df_3['label'].map(label_to_source)\n",
    "\n",
    "# Select only the desired columns: \"text\" and \"source\"\n",
    "new_df_3 = df_3[['text', 'source']].copy()\n",
    "\n",
    "dataframes.append(new_df_3)\n",
    "new_df_3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_csv(\"LLM.csv\")\n",
    "df_4.rename(columns = {\"Text\": \"text\", \"Label\": \"source\"}, inplace=True)\n",
    "\n",
    "# Create a mapping for the label values\n",
    "label_to_source = {\n",
    "    \"ai\": \"ai\",\n",
    "    \"student\": \"human\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the \"source\" column\n",
    "df_4['source'] = df_4['source'].map(label_to_source)\n",
    "df_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quinto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "human    2100\n",
      "ai       1953\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced electromagnetic potentials are indi...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This research paper investigates the question ...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We give an algorithm for finding network enc...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The paper presents an efficient centralized bi...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We introduce an exponential random graph mod...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0    Advanced electromagnetic potentials are indi...  human\n",
       "1  This research paper investigates the question ...     ai\n",
       "2    We give an algorithm for finding network enc...  human\n",
       "3  The paper presents an efficient centralized bi...     ai\n",
       "4    We introduce an exponential random graph mod...  human"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5 = pd.read_csv(\"data_set.csv\")\n",
    "df_5.rename(columns = {\"abstract\": \"text\", \"is_ai_generated\": \"source\"}, inplace=True)\n",
    "df_5.drop(columns=['title','ai_generated'], inplace=True)\n",
    "\n",
    "# Create a mapping for the label values\n",
    "label_to_source = {\n",
    "    1: \"ai\",\n",
    "    0: \"human\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the \"source\" column\n",
    "df_5['source'] = df_5['source'].map(label_to_source)\n",
    "print(df_5['source'].value_counts())\n",
    "dataframes.append(df_5)\n",
    "df_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sexto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "ai       800\n",
      "human    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_6_news_gpt = pd.read_pickle(\"en_news_gpt_features_df.pkl\")\n",
    "df_6_news_human = pd.read_pickle(\"en_news_human_features_df.pkl\")\n",
    "df_6_wiki_gpt = pd.read_pickle(\"en_wiki_gpt_features_df.pkl\")\n",
    "df_6_wiki_human = pd.read_pickle(\"en_wiki_human_features_df.pkl\")\n",
    "\n",
    "df_6_news_gpt = df_6_news_gpt[['text']]\n",
    "df_6_news_gpt['source'] = 'ai'\n",
    "\n",
    "df_6_news_human = df_6_news_human[['text']]\n",
    "df_6_news_human['source'] = 'human'\n",
    "\n",
    "df_6_wiki_gpt = df_6_wiki_gpt[['text']]\n",
    "df_6_wiki_gpt['source'] = 'ai'\n",
    "\n",
    "df_6_wiki_human = df_6_wiki_human[['text']]\n",
    "df_6_wiki_human['source'] = 'human'\n",
    "\n",
    "df_6 = pd.concat([df_6_news_gpt, df_6_news_human, df_6_wiki_gpt, df_6_wiki_human], ignore_index=True)\n",
    "dataframes.append(df_6)\n",
    "print(df_6['source'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coisas geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cell cycle, or cell-division cycle, is the...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The cell cycle is the process by which a cell ...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Photons, in many atomic models in physics, are...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A photon is a fundamental particle of light an...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the theory of plate tectonics, Ea...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  The cell cycle, or cell-division cycle, is the...  human\n",
       "1  The cell cycle is the process by which a cell ...     ai\n",
       "2  Photons, in many atomic models in physics, are...  human\n",
       "3  A photon is a fundamental particle of light an...     ai\n",
       "4  According to the theory of plate tectonics, Ea...  human"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gerado_cie = pd.read_csv(\"scientific_texts.csv\")\n",
    "df_gerado_ai = pd.read_csv(\"processed_scientific_texts0.csv\")\n",
    "df_gerado_ai1 = pd.read_csv(\"processed_scientific_texts1.csv\")\n",
    "df_gerado_ai2 = pd.read_csv(\"processed_scientific_texts2.csv\")\n",
    "df_gerado_ai3 = pd.read_csv(\"processed_scientific_texts3.csv\")\n",
    "\n",
    "dataframes.append(df_gerado_cie.head(400))\n",
    "dataframes.append(df_gerado_ai.head(200))\n",
    "dataframes.append(df_gerado_ai1.head(200))\n",
    "dataframes.append(df_gerado_ai2.head(200))\n",
    "dataframes.append(df_gerado_ai3.head(200))\n",
    "\n",
    "df_1 = pd.read_csv(\"dataset1_inputs.csv\",sep=\"\\t\")\n",
    "df_1_out = pd.read_csv(\"dataset1_outputs.csv\",sep=\"\\t\")\n",
    "df_1['source'] = df_1_out['Label']\n",
    "# rename Text to text\n",
    "df_1.rename(columns={\"Text\": \"text\"}, inplace=True)\n",
    "# map values Human to human and AI to ai\n",
    "label_to_source = {\n",
    "    \"Human\": \"human\",\n",
    "    \"AI\": \"ai\"\n",
    "}\n",
    "# Apply the mapping to create the \"source\" column\n",
    "df_1['source'] = df_1['source'].map(label_to_source)\n",
    "df_1 = df_1[['text', 'source']]\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntar tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5249 entries, 0 to 5248\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5249 non-null   object\n",
      " 1   source  5248 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 82.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.info()\n",
    "# take \"\\n\" out of the text\n",
    "df['text'] = df['text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5247 entries, 0 to 5248\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5247 non-null   object\n",
      " 1   source  5246 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 123.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"human_or_ai_dataset_sub3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
