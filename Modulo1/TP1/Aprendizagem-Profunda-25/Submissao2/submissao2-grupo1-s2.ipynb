{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, é o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras  # Optional, but good for structured access\n",
    "\n",
    "# Load the saved predictor\n",
    "predictor = tf.keras.models.load_model('../code/nn_tensorflow/best_model_rnn_lstm.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded competition input data with shape: (100, 2)\n",
      "Columns: Index(['ID', 'Text'], dtype='object')\n",
      "Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras import preprocessing\n",
    "# Load competition data\n",
    "max_features = 10000  # Tamanho do vocabulário\n",
    "maxlen = 120  # Tamanho máximo das sequências\n",
    "\n",
    "competition_input = pd.read_csv('dataset3_inputs.csv', sep=';')\n",
    "print(f\"Loaded competition input data with shape: {competition_input.shape}\")\n",
    "print(f\"Columns: {competition_input.columns}\")\n",
    "\n",
    "# Load tokenizer from file\n",
    "with open('../code/nn_tensorflow/tokenizerRNN.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"Tokenizer loaded successfully!\")\n",
    "\n",
    "# Separar os textos das labels\n",
    "texts = competition_input['Text'].values\n",
    "# Converter os textos para sequências de inteiros\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "# Padding para uniformizar tamanhos\n",
    "x_data = preprocessing.sequence.pad_sequences(sequences, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Sample Predictions: ['AI', 'AI', 'Human', 'Human', 'AI', 'AI', 'Human', 'Human', 'Human', 'Human']\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "raw_predictions = predictor.predict(x_data)\n",
    "\n",
    "# Convert probabilities to class labels (0 or 1)\n",
    "predicted_labels = (raw_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Map numerical predictions to text labels\n",
    "label_map = {0: \"Human\", 1: \"AI\"}\n",
    "predictions = [label_map[label] for label in predicted_labels]\n",
    "\n",
    "# Print some sample predictions\n",
    "print(\"Sample Predictions:\", predictions[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions:\n",
      "     ID  Label\n",
      "0  D3-1     AI\n",
      "1  D3-2     AI\n",
      "2  D3-3  Human\n",
      "3  D3-4  Human\n",
      "4  D3-5     AI\n",
      "\n",
      "Predictions saved to competition_predictions_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Create output dataframe\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': competition_input['ID'],\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "print(\"\\nSample predictions:\")\n",
    "print(output_df.head())\n",
    "\n",
    "# Save predictions to CSV\n",
    "output_df.to_csv('submissao2-grupo1-s2.csv', sep='\\t', index=False)\n",
    "print(\"\\nPredictions saved to competition_predictions_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on dataset1: nan\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "             Human    AI\n",
      "True Human:      0      0\n",
      "     AI:         0      0\n"
     ]
    }
   ],
   "source": [
    "# Optional: Verify against the provided dataset1_outputs.csv\n",
    "try:\n",
    "    ground_truth = pd.read_csv('dataset2_disclosed_outputs.csv', sep='\\t')\n",
    "    merged = output_df.merge(ground_truth, on='ID', suffixes=('_pred', '_true'))\n",
    "    accuracy = (merged['Label_pred'] == merged['Label_true']).mean()\n",
    "    print(f\"\\nAccuracy on dataset1: {accuracy:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(merged['Label_true'], merged['Label_pred'], labels=['Human', 'AI'])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"             Human    AI\")\n",
    "    print(f\"True Human:  {cm[0][0]:5d}  {cm[0][1]:5d}\")\n",
    "    print(f\"     AI:     {cm[1][0]:5d}  {cm[1][1]:5d}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not verify against ground truth: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
