{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\"\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed) # Python\n",
    "    np.random.seed(seed)  # Numpy, Ã© o gerador utilizado pelo sklearn\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # sistema operativo\n",
    "\n",
    "set_seed(25)\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonug\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\initializers\\initializers.py:121: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras  # Optional, but good for structured access\n",
    "\n",
    "# Load the saved predictor\n",
    "\n",
    "predictor = ktrain.load_predictor('../code/nn_tensorflow/bertao')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded competition input data with shape: (100, 2)\n",
      "Columns: Index(['ID', 'Text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load competition data\n",
    "competition_input = pd.read_csv('dataset3_inputs.csv', sep=';')\n",
    "print(f\"Loaded competition input data with shape: {competition_input.shape}\")\n",
    "print(f\"Columns: {competition_input.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert prediction to proper capitalization\n",
    "def format_prediction(pred):\n",
    "    if pred.lower() == 'ai':\n",
    "        return 'AI'\n",
    "    elif pred.lower() == 'human':\n",
    "        return 'Human'\n",
    "    else:\n",
    "        return pred  # Return as-is for any other values\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "for text in competition_input['Text']:\n",
    "    # Get prediction - returns the class name\n",
    "    pred = predictor.predict(text)\n",
    "    # Convert to proper capitalization\n",
    "    formatted_pred = format_prediction(pred)\n",
    "    predictions.append(formatted_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions:\n",
      "     ID  Label\n",
      "0  D3-1     AI\n",
      "1  D3-2     AI\n",
      "2  D3-3     AI\n",
      "3  D3-4  Human\n",
      "4  D3-5  Human\n",
      "\n",
      "Predictions saved to competition_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Create output dataframe\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': competition_input['ID'],\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "print(\"\\nSample predictions:\")\n",
    "print(output_df.head())\n",
    "\n",
    "# Save predictions to CSV\n",
    "output_df.to_csv('submissao2-grupo1-s1.csv', sep='\\t', index=False)\n",
    "print(\"\\nPredictions saved to competition_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on dataset1: 0.6800\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "             Human    AI\n",
      "True Human:     12     14\n",
      "     AI:         2     22\n"
     ]
    }
   ],
   "source": [
    "# Optional: Verify against the provided dataset1_outputs.csv\n",
    "try:\n",
    "    ground_truth = pd.read_csv('dataset2_disclosed_outputs.csv', sep='\\t')\n",
    "    merged = output_df.merge(ground_truth, on='ID', suffixes=('_pred', '_true'))\n",
    "    accuracy = (merged['Label_pred'] == merged['Label_true']).mean()\n",
    "    print(f\"\\nAccuracy on dataset1: {accuracy:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(merged['Label_true'], merged['Label_pred'], labels=['Human', 'AI'])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"             Human    AI\")\n",
    "    print(f\"True Human:  {cm[0][0]:5d}  {cm[0][1]:5d}\")\n",
    "    print(f\"     AI:     {cm[1][0]:5d}  {cm[1][1]:5d}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not verify against ground truth: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
