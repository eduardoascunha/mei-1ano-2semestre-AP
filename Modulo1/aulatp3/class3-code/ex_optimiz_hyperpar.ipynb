{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of hyperparameter optimization in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxsyA9Wni-b-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import Input, optimizers\n",
    "\n",
    "## function to setup model - assuming multiclass classification problem\n",
    "def setup_model(topo, dropout_rate, input_size, output_size):\n",
    "    model = Sequential()\n",
    "    model.add(Input( (input_size, ) ))\n",
    "    model.add(Dense(topo[0], activation=\"relu\") )\n",
    "    if dropout_rate > 0: model.add(Dropout(dropout_rate))\n",
    "    for i in range(1,len(topo)):        \n",
    "        model.add(Dense(topo[i], activation=\"relu\"))\n",
    "        if dropout_rate > 0: model.add(Dropout(dropout_rate))    \n",
    "    model.add(Dense(output_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "## training the DNN - takes algorithm (string) and learning rate; data (X, y), epochs and batch size\n",
    "def train_dnn(model, alg, lr, Xtrain, Ytrain, epochs = 5, batch_size = 64):\n",
    "    if alg == \"adam\":\n",
    "        optimizer = optimizers.Adam(learning_rate = lr)\n",
    "    elif alg == \"rmsprop\":\n",
    "        optimizer = optimizers.RMSprop(learning_rate = lr)\n",
    "    elif alg == \"sgd_momentum\":\n",
    "        optimizer = optimizers.SGD(learning_rate = lr, momentum = 0.9)\n",
    "    else: optimizer = optimizers.SGD(learning_rate = lr)\n",
    "        \n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    model.fit(Xtrain, Ytrain, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "## optimizing parameters: topology, algorithm, learning rate, dropout\n",
    "## randomized search optimization with maximum iterations\n",
    "## takes as input: dictionary with params to optimizae and possible values; training data(X,y), validation data (X,y), iterations, epochs for training\n",
    "def dnn_optimization(opt_params, Xtrain, Ytrain, Xval, Yval, iterations = 10, epochs = 5, verbose = True):\n",
    "    from random import choice\n",
    "  \n",
    "    if verbose: \n",
    "        print(\"Topology\\tDropout\\tAlgorithm\\tLRate\\tValLoss\\tValAcc\\n\")\n",
    "    best_acc = None\n",
    "    \n",
    "    input_size = Xtrain.shape[1]\n",
    "    output_size = Ytrain.shape[1]\n",
    "    \n",
    "    if \"topology\" in opt_params:\n",
    "        topologies = opt_params[\"topology\"]\n",
    "    else: topologies = [[100]]\n",
    "    if \"algorithm\" in opt_params:\n",
    "        algs = opt_params[\"algorithm\"]\n",
    "    else: algs = [\"adam\"]\n",
    "    if \"lr\" in opt_params:\n",
    "        lrs = opt_params[\"lr\"]\n",
    "    else: lrs = [0.001]\n",
    "    if \"dropout\" in opt_params:\n",
    "        dropouts = opt_params[\"dropout\"]\n",
    "    else: dropouts= [0.0]\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        topo = choice(topologies)\n",
    "        dropout_rate = choice(dropouts)\n",
    "        dnn = setup_model (topo, dropout_rate, input_size, output_size)\n",
    "        alg = choice(algs)\n",
    "        lr = choice(lrs)\n",
    "        dnn = train_dnn(dnn, alg, lr, Xtrain, Ytrain, epochs, 128)\n",
    "        val_loss, val_acc = dnn.evaluate(Xval, Yval, verbose = 0)\n",
    "        \n",
    "        if verbose: \n",
    "            print(topo, \"\\t\", dropout_rate, \"\\t\", alg, \"\\t\", lr, \"\\t\", val_loss, \"\\t\", val_acc)\n",
    "        \n",
    "        if best_acc is None or val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_config = (topo, dropout_rate, alg, lr)\n",
    "        \n",
    "    return best_config, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with MNIST dataset - DNNs with hyperparameters optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-4j0VvLEjK-X",
    "outputId": "4e08fe90-79c5-426f-fb15-9fd60af192f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "60000 10000\n",
      "(50000, 784) (10000, 784) (10000, 784)\n",
      "50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "print(len(train_labels), len(test_labels))\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "X_test = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "X_tr = train_images[:50000,]\n",
    "X_val = train_images[50000:,]\n",
    "y_tr = train_labels[:50000]\n",
    "y_val = train_labels[50000:,]\n",
    "\n",
    "print(X_tr.shape, X_val.shape, X_test.shape)\n",
    "print(len(y_tr), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "hJnLtsYUmDhA",
    "outputId": "6be431e1-6f49-4b76-fc9b-95016f439d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology\tDropout\tAlgorithm\tLRate\tValLoss\tValAcc\n",
      "\n",
      "[250, 100] \t 0 \t sgd_momentum \t 0.001 \t 0.17259380221366882 \t 0.954200029373169\n",
      "[100] \t 0.2 \t sgd_momentum \t 0.001 \t 0.22359754145145416 \t 0.9387999773025513\n",
      "[100] \t 0 \t sgd_momentum \t 0.001 \t 0.2265009731054306 \t 0.9361000061035156\n",
      "[250, 100] \t 0 \t adam \t 0.001 \t 0.1012963280081749 \t 0.9797000288963318\n",
      "[250] \t 0 \t adam \t 0.001 \t 0.08610545843839645 \t 0.9779000282287598\n",
      "[250, 100] \t 0 \t rmsprop \t 0.001 \t 0.12497837096452713 \t 0.9818999767303467\n",
      "[250, 100] \t 0.2 \t adam \t 0.001 \t 0.08458640426397324 \t 0.98089998960495\n",
      "[250] \t 0.2 \t sgd_momentum \t 0.001 \t 0.2134183794260025 \t 0.9417999982833862\n",
      "[100] \t 0.5 \t adam \t 0.01 \t 0.13463562726974487 \t 0.96670001745224\n",
      "[250] \t 0.2 \t sgd_momentum \t 0.001 \t 0.21207495033740997 \t 0.9420999884605408\n",
      "[100] \t 0.2 \t sgd_momentum \t 0.001 \t 0.22130459547042847 \t 0.939300000667572\n",
      "[250] \t 0.5 \t adam \t 0.001 \t 0.06946832686662674 \t 0.9815000295639038\n",
      "[250, 100] \t 0.5 \t adam \t 0.01 \t 0.17295067012310028 \t 0.9623000025749207\n",
      "[100] \t 0.2 \t rmsprop \t 0.001 \t 0.08799609541893005 \t 0.9763000011444092\n",
      "[100] \t 0.2 \t adam \t 0.01 \t 0.15082670748233795 \t 0.9726999998092651\n",
      "[250] \t 0.2 \t rmsprop \t 0.001 \t 0.08020636439323425 \t 0.9801999926567078\n",
      "[250] \t 0 \t adam \t 0.01 \t 0.3429984152317047 \t 0.9710999727249146\n",
      "[250] \t 0.5 \t rmsprop \t 0.001 \t 0.07453557103872299 \t 0.98089998960495\n",
      "[100] \t 0 \t sgd_momentum \t 0.01 \t 0.09370224922895432 \t 0.9721999764442444\n",
      "[250, 100] \t 0.5 \t sgd_momentum \t 0.01 \t 0.07884146273136139 \t 0.9778000116348267\n",
      "Best configuration: ([250, 100], 0, 'rmsprop', 0.001)\n",
      "Best validation accuracy: 0.9818999767303467\n"
     ]
    }
   ],
   "source": [
    "opt_pars = {\"topology\":[[100], [100,50], [250], [250,100]],\n",
    "            \"algorithm\": [ \"adam\", \"rmsprop\", \"sgd_momentum\"],\n",
    "            \"lr\": [0.01, 0.001],\n",
    "            \"dropout\": [0, 0.2, 0.5]}\n",
    "\n",
    "best_config, best_val_acc = dnn_optimization(opt_pars, X_tr, y_tr, X_val, y_val, iterations = 20, epochs = 20)  \n",
    "print(\"Best configuration:\", best_config)\n",
    "print(\"Best validation accuracy:\", best_val_acc) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7IL7shHMouMQ",
    "outputId": "0c171279-660a-41e9-b336-d2aae7efbac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set metrics: 0.08328428864479065 0.9789999723434448\n"
     ]
    }
   ],
   "source": [
    "# take best configuration and retrain with whole training set\n",
    "# evaluate error on holdout test set\n",
    "best_model = setup_model(best_config[0], best_config[1], X_tr.shape[1], y_tr.shape[1])\n",
    "best_model = train_dnn(best_model, best_config[2], best_config[3], train_images, train_labels)\n",
    "\n",
    "test_loo, test_acc = best_model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test set metrics:\", test_loo, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ex_optimiz_hyperpar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
