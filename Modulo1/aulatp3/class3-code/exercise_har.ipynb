{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15746453",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "*Human Activity Recognition using Smartphones* dataset\n",
    "\n",
    "Dataset description:\n",
    "\n",
    "*The experiments have been carried out with a group of 30 volunteers. Each person performed six activities\n",
    "(WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone.\n",
    "Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity.\n",
    "The experiments have been video-recorded to label the data manually.*\n",
    "\n",
    "**Variables:**\n",
    "For each record in the dataset it is provided:\n",
    "* A 561-feature vector with time and frequency domain variables.\n",
    "* Its activity label.\n",
    "* An identifier of the subject who carried out the experiment.\n",
    "\n",
    "More details at: https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32b7a9",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c5743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e5e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = ''  ## put here folder where the file HAR_clean.csv is located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79540a9d",
   "metadata": {},
   "source": [
    "Load the dataset that was created in the last session: \"HAR_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b430687",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(os.path.join(folder, 'HAR_clean.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f435d7",
   "metadata": {},
   "source": [
    "Divide into input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9c1de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 561)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = all_data.iloc[:,:-2]\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b42b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = all_data.iloc[:,-1]\n",
    "output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477cce00",
   "metadata": {},
   "source": [
    "Divide the data into train and test, keeping 30% for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1cf55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7209, 561) (7209,)\n",
      "(3090, 561) (3090,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.3)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa30e7f",
   "metadata": {},
   "source": [
    "### Best shallow ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7beffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':['linear', 'rbf'], 'C':[1, 10, 100,1000], 'gamma':[0.01, 0.001]}\n",
    "\n",
    "svm_model_d = svm.SVC()\n",
    "opt_model_d = GridSearchCV(svm_model_d, parameters)\n",
    "\n",
    "opt_model_d.fit(X_train, y_train)\n",
    "print (opt_model_d.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf6296f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938511326860842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_model_d.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce6f06",
   "metadata": {},
   "source": [
    "### Deep Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47623f3b",
   "metadata": {},
   "source": [
    "**Ex. 1** - Train a Deep Neural Network model for this dataset and compare its performance with the shallow models from previous sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f9ce563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(y_train)\n",
    "\n",
    "y_train_encoded = le.transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed3aeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93bbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7df31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fceea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd4f2087",
   "metadata": {},
   "source": [
    "**Ex. 2** - Play with the different parameters (topologies, training algorithms, etc) and check their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf20652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27134c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa98486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497c6259",
   "metadata": {},
   "source": [
    "**Ex. 3** - Implement an hyperparameter optimization pipeline using the following functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9ea6c",
   "metadata": {},
   "source": [
    "Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90e1478c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxsyA9Wni-b-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "## function to setup model - assuming multiclass classification problem\n",
    "def setup_model(topo, dropout_rate, input_size, output_size):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(topo[0], activation=\"relu\", input_dim = input_size))\n",
    "    if dropout_rate > 0: model.add(Dropout(dropout_rate))\n",
    "    for i in range(1,len(topo)):        \n",
    "        model.add(Dense(topo[i], activation=\"relu\"))\n",
    "        if dropout_rate > 0: model.add(Dropout(dropout_rate))    \n",
    "    model.add(Dense(output_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "## training the DNN - takes algorithm (string) and learning rate; data (X, y), epochs and batch size\n",
    "def train_dnn(model, alg, lr, Xtrain, Ytrain, epochs = 5, batch_size = 64):\n",
    "    if alg == \"adam\":\n",
    "        optimizer = optimizers.Adam(learning_rate = lr)\n",
    "    elif alg == \"rmsprop\":\n",
    "        optimizer = optimizers.RMSprop(learning_rate = lr)\n",
    "    elif alg == \"sgd_momentum\":\n",
    "        optimizer = optimizers.SGD(learning_rate = lr, momentum = 0.9)\n",
    "    else: optimizer = optimizers.SGD(learning_rate = lr)\n",
    "        \n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    model.fit(Xtrain, Ytrain, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "## optimizing parameters: topology, algorithm, learning rate, dropout\n",
    "## randomized search optimization with maximum iterations\n",
    "## takes as input: dictionary with params to optimizae and possible values; training data(X,y), validation data (X,y), iterations, epochs for training\n",
    "def dnn_optimization(opt_params, Xtrain, Ytrain, Xval, Yval, iterations = 10, epochs = 5, verbose = True):\n",
    "    from random import choice\n",
    "  \n",
    "    if verbose: \n",
    "        print(\"Topology\\tDropout\\tAlgorithm\\tLRate\\tValLoss\\tValAcc\\n\")\n",
    "    best_acc = None\n",
    "    \n",
    "    input_size = Xtrain.shape[1]\n",
    "    output_size = Ytrain.shape[1]\n",
    "    \n",
    "    if \"topology\" in opt_params:\n",
    "        topologies = opt_params[\"topology\"]\n",
    "    else: topologies = [[100]]\n",
    "    if \"algorithm\" in opt_params:\n",
    "        algs = opt_params[\"algorithm\"]\n",
    "    else: algs = [\"adam\"]\n",
    "    if \"lr\" in opt_params:\n",
    "        lrs = opt_params[\"lr\"]\n",
    "    else: lrs = [0.001]\n",
    "    if \"dropout\" in opt_params:\n",
    "        dropouts = opt_params[\"dropout\"]\n",
    "    else: dropouts= [0.0]\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        topo = choice(topologies)\n",
    "        dropout_rate = choice(dropouts)\n",
    "        dnn = setup_model (topo, dropout_rate, input_size, output_size)\n",
    "        alg = choice(algs)\n",
    "        lr = choice(lrs)\n",
    "        dnn = train_dnn(dnn, alg, lr, Xtrain, Ytrain, epochs, 128)\n",
    "        val_loss, val_acc = dnn.evaluate(Xval, Yval, verbose = 0)\n",
    "        \n",
    "        if verbose: \n",
    "            print(topo, \"\\t\", dropout_rate, \"\\t\", alg, \"\\t\", lr, \"\\t\", val_loss, \"\\t\", val_acc)\n",
    "        \n",
    "        if best_acc is None or val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_config = (topo, dropout_rate, alg, lr)\n",
    "        \n",
    "    return best_config, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a1387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc132f2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "hJnLtsYUmDhA",
    "outputId": "6be431e1-6f49-4b76-fc9b-95016f439d4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11566e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7IL7shHMouMQ",
    "outputId": "0c171279-660a-41e9-b336-d2aae7efbac0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccf817f7",
   "metadata": {},
   "source": [
    "**Ex. 4** - Comment on the results obtained !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83779c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
